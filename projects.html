<!DOCTYPE html>
<html lang="en">
<head>
    <title>Projects - Felix Brunner</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href="https://felixbrunner.github.io/assets/images/icon.png" rel="icon">

<link rel="canonical" href="https://felixbrunner.github.io/projects">

        <meta name="author" content="Felix Brunner" />




    <!-- Bootstrap -->
        <link rel="stylesheet" href="https://felixbrunner.github.io/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="https://felixbrunner.github.io/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="https://felixbrunner.github.io/theme/css/pygments/native.css" rel="stylesheet">
        <link href="https://felixbrunner.github.io/theme/css/typogrify.css" rel="stylesheet">
    <link rel="stylesheet" href="https://felixbrunner.github.io/theme/css/style.css" type="text/css"/>
        <link href="https://felixbrunner.github.io/../static/custom.css" rel="stylesheet">



    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id='G-2Y1PCGBZSE'"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-2Y1PCGBZSE');
    </script>
    <!-- End Google Analytics Code -->
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->

</head>
<body>

<div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://felixbrunner.github.io/" class="navbar-brand">
<img class="img-responsive pull-left gap-right" src="https://felixbrunner.github.io/assets/images/icon.png" width="20px"/>             </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="https://felixbrunner.github.io/about">
                             About
                          </a></li>
                         <li><a href="https://felixbrunner.github.io/contact">
                             Contact
                          </a></li>
                         <li class="active"><a href="https://felixbrunner.github.io/projects">
                             Projects
                          </a></li>
                         <li><a href="https://felixbrunner.github.io/research">
                             Research
                          </a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<style>
	#banner{
	    background-image:url("https://felixbrunner.github.io/assets/images/banner.png");
	}
</style>

<div id="banner">
	<div class="container">
		<div class="copy">
			<h1>Felix Brunner</h1>
				<p class="intro">My personal website</p>
		</div>
	</div>
</div><!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content" class="body">
        <h1 class="entry-title">Projects</h1>
        
        <div class="entry-content">
            <p>This page presents descriptions of some of the <strong>data projects</strong> I have been involved&nbsp;in.</p>
<p><br/><br/><br/></p>
<h2>Quality Prediction Based on Sensor Time Series&nbsp;Recordings</h2>
<!-- with [Bond3D](https://www.bond3d.com/), [Fraunhofer IPT](https://www.ipt.fraunhofer.de/), and [dida machine learning](https://dida.do/), 2021-2023 -->

<!-- <p align="center"><img src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*9Xopehn3Z_V8aCr-ZVGCzQ.png" alt="drawing" width="700"/></p> -->
<p align="center"><img src="assets/drawings/xrocket-full.png" alt="drawing" width="700"/></p>

<ul>
<li>
<p><strong>Challenge:</strong>
A <strong>manufacturing company</strong> needed to analyze large volumes of <strong>time series data</strong> from production machines to understand if there are usable signals to predict the quality of final products. The challenge was finding meaningful patterns in the vast sensory data associated with single outcome labels, and ensuring the model&#8217;s interpretability for production&nbsp;engineers.</p>
</li>
<li>
<p><strong>Solution:</strong>
The project involved conceptualizing and implementing <strong>data pipelines</strong> to filter, connect, and integrate multiple data sources for machine learning model development. The processed data served to train <code>PyTorch</code> neural network models, with multiple predictive models tested, including simple statistical approaches and <strong>deep convolutional neural networks</strong>. A strong emphasis was placed on <strong>explainable <span class="caps">AI</span></strong> to ensure production engineers could interpret the modelâ€™s findings. Therefore, the state-of-the-art <strong>time series encoder model <span class="caps">ROCKET</span></strong> was augmented to add explainability and provide insights into the driving signals and&nbsp;patterns.</p>
</li>
<li>
<p><strong>Impact:</strong>
The project delivered <strong>actionable insights</strong> into production processes in the form of a <strong>ranking of the top 5 most important signals</strong>, ultimately helping engineers optimize operations and improve product quality. The development of the <strong>explainable <span class="caps">ROCKET</span></strong> encoder model allowed for better adoption and understanding of the&nbsp;outputs.</p>
<p><details>
<br>
<summary><i>Click for additional information</i></summary></p>
<ul>
<li>Details and Links:
For further details on the model architecture and implementation, refer to my three-part article series on the X-<span class="caps">ROCKET</span> architecture (<a href="https://medium.com/dida-machine-learning/explainable-time-series-classification-with-x-rocket-3087b912a08d?source=friends_link&amp;sk=c9e42fa9bfe32cd58f804673ca5aef8c">Part 1</a>, <a href="https://medium.com/dida-machine-learning/inside-x-rocket-explaining-the-explainable-rocket-534b104c4a08?source=friends_link&amp;sk=4222cf1591d49181eff368f97d0bdee0">Part 2</a>, and <a href="https://medium.com/dida-machine-learning/x-rocket-to-the-moon-c2848e740243?source=friends_link&amp;sk=a8428dac4867839dc22007196c6a4f87">Part 3</a>), and the corresponding <a href="https://github.com/dida-do/xrocket">code repository</a>.</li>
<li>Stack:
<code>PyTorch</code>, <code>CNNs</code>, <code>ROCKET</code>, <code>git</code>, <code>Time series classification</code>, <code>explainable AI</code>, <code>Python</code>, <code>numpy</code>, <code>matplotlib</code>
</details></li>
</ul>
</li>
</ul>
<p><br/><br/><br/></p>
<h2>Visual Contamination Detection in Industrial 3D&nbsp;Printing</h2>
<!-- with [Bond3D](https://www.bond3d.com/), [Fraunhofer IPT](https://www.ipt.fraunhofer.de/), and [dida machine learning](https://dida.do/), 2021-2023 -->

<p align="center"><img src="https://cdn.dida.do/labelled-1687853311-(1).jpg" alt="drawing" width="700"/></p>

<ul>
<li>
<p><strong>Challenge:</strong>
In industrial additive <strong>manufacturing</strong>, identifying contamination during the printing process is critical to prevent machine damage and optimize productivity. The objective of this project is to automate the process monitoring by developing a <strong>computer vision</strong> algorithm that detects pollution of production machines from pre-installed infrared cameras in real-time. However, data heterogeneity across different machines and limited data availability posed significant challenges for building an effective monitoring&nbsp;system.</p>
</li>
<li>
<p><strong>Solution:</strong>
The project began with <strong>workshops</strong> conducted alongside domain experts to define the use case and evaluate the potential of machine learning in the production environment. Systematic data collection and <strong>pre-processing</strong> were guided to prepare datasets for model training, and we created a <strong>custom labeling tool</strong> to annotate image datasets for training. A <strong>ResNet convolutional neural network</strong> was developed in <code>PyTorch</code> to detect machine contamination in real-time using computer vision, with data augmentation techniques applied to address data heterogeneity and limited data availability. The final model was containerized using <code>Docker</code> with <code>FastAPI</code> endpoints for <strong>deployment</strong>, ensuring seamless integration with the production&nbsp;machines.</p>
</li>
<li>
<p><strong>Impact:</strong>
The project delivered a <strong>production-ready system</strong> capable of informing operators of potential faults in real-time with a <strong>success rate of 95%</strong>, preventing machine damage and reducing&nbsp;downtime.</p>
<p><details>
<br>
<summary><i>Click for additional information</i></summary></p>
<ul>
<li>Details and Links:
For more information on the machine learning use case and the overall project, refer to the project pages of <a href="https://dida.do/projects/contamination-detection-in-industrial-3d-printing">dida</a>, <a href="https://www.ipt.fraunhofer.de/de/projekte/ai-gent3d.html">Fraunhofer <span class="caps">IPT</span></a>, and <a href="https://www.zukunft-der-wertschoepfung.de/projekte/eranet-ki-gesttztes-generatives-3d-drucken-manunet-aigent3d/"><span class="caps">BMBF</span></a>.
Additionally, details about the labeling tool created for the annotation of the image dataset can be found in <a href="https://medium.com/dida-machine-learning/how-to-implement-an-image-labeling-tool-in-a-jupyter-notebook-4aa4099addba?source=friends_link&amp;sk=3ee7eabd27f2bf29226fbd8e970cc1f6">my article</a>, and the corresponding code <a href="https://github.com/dida-do/public/tree/master/labelingtool">repository</a>.</li>
<li>Stack: 
<code>PyTorch</code>, <code>Convolutional neural network (CNN)</code>, <code>Docker</code>, <code>git</code>, <code>OpenCV</code>, <code>FastAPI</code>, <code>Computer vision</code>, <code>pytorch-lightning</code>, <code>ipywidgets</code>, <code>Python</code>
</details></li>
</ul>
</li>
</ul>
<p><br/><br/><br/></p>
<h2>Automated Question Answering via Document&nbsp;Retrieval</h2>
<!-- with [dida machine learning](https://dida.do/), 2022 -->

<p align="center"><img src="https://files.readme.io/0343fcb-RAG_2.png" alt="drawing" width="700"/></p>

<ul>
<li>
<p><strong>Challenge:</strong>
Company knowledge is often scattered in internal documentation rather than accessible for employees through familiar channels. The project therefore aimed at creating a <strong>chatbot</strong> for <strong>question answering (<span class="caps">QA</span>)</strong> based on on internal documents into the communication platform used by the&nbsp;employees.</p>
</li>
<li>
<p><strong>Solution:</strong>
An initial demo was developed using <strong>extractive <span class="caps">QA</span></strong> and <strong>semantic search</strong> to identify answers in internal documents. As the project evolved, the solution expanded to incorporate <strong>generative <span class="caps">QA</span></strong> by integrating <strong>LLMs</strong> with <strong>retrieval augmented generation (<span class="caps">RAG</span>)</strong>, allowing for more sophisticated and dynamic responses. The project team leveraged <code>huggingface</code> and <code>Haystack</code> for implementation. Additionally, a custom codebase was developed to connect to the Slack platform <span class="caps">API</span>, and regular updates on rapid <strong><span class="caps">NLP</span></strong> advancements were shared with the team to ensure alignment with the latest research and industry&nbsp;trends.</p>
</li>
<li>
<p><strong>Impact:</strong>
The project successfully delivered a <strong>proof-of-concept</strong>, enhancing employee productivity by providing instant access to relevant information stored in the internal documentation base. The solution promises to streamline internal communication and provided valuable insights for future exploration of <span class="caps">LLM</span>-based <span class="caps">QA</span>&nbsp;solutions.</p>
<p><details>
<br>
<summary><i>Click for additional information</i></summary></p>
<p><!-- - Details and Links:
The project journey began with an early demo showcasing extractive question answering based on semantic search, still accessible online <a href="https://dida.do/demos/question-answering">here</a>. Subsequent stages explored full-fledged generative question answering using large language models (LLMs) and retrieval augmented generation (RAG) techniques. -->
- Stack: 
<code>huggingface transformers</code>, <code>haystack</code>, <code>LLM</code>, <code>document retrieval</code>, <code>semantic search</code>, <code>question answering</code>, <code>BERT</code>, <code>git</code>, <code>beautifulsoup</code>, <code>python</code>, <code>API</code>
</details></p>
</li>
</ul>
<p><br/><br/><br/></p>
<h2>Estimation and Analysis of Variance Spillover&nbsp;Networks</h2>
<!-- with [Ruben Hipp](https://sites.google.com/view/rubenhipp/home) at [Nova SBE](https://www.novasbe.unl.pt/en/) 2022 -->

<p align="center"><img src="/assets/graphs/contour_var.png" alt="drawing" width="550"/></p>

<ul>
<li>
<p><strong>Challenge:</strong>
The project aimed to develop robust models for analyzing large-dimensional time series datasets as networks. A key challenge is to develop machine learnig methodology for <strong>multivariate time-series forecasting</strong> such that the parameters have an econometric interpretation when conducting rigorous <strong>statistical analysis</strong>.</p>
</li>
<li>
<p><strong>Solution:</strong>
The solution involved acquiring financial time series data from <code>SQL</code> databases and developing a custom data <strong>pre-processing pipeline</strong> to prepare the data for estimation over rolling time intervals. Object-oriented code leveraging <code>scikit-learn</code> and <code>glmnet</code> enabled the robust estimation and comparison of <strong>regularized statistical learning algorithms</strong> in <span class="caps">VAR</span> models with <strong>cross-validation</strong>. Extensive statistical analyses and <strong>visualizations</strong> using <code>statsmodels</code>, <code>networkx</code> and<code>matplotlib</code> then offered empirical insights that were recorded in academic research&nbsp;papers.</p>
</li>
<li>
<p><strong>Impact:</strong>
The project successfully produced several <strong>research papers</strong>, including an acclaimed publication in <em>Quantitative Economics</em>. The developed methods and empirical findings significantly advanced the understanding of time series analysis and forecasting, particularly in network estimation and economic spillovers. The work continues to contribute to the field, with further papers under&nbsp;review.</p>
<p><details>
<br>
<summary><i>Click for additional information</i></summary></p>
<ul>
<li>Details and Links:
For more information on the research papers and the underlying code repository, visit the <a href="research">research page</a> and the <a href="https://github.com/felixbrunner/euraculus">GitHub repository</a>. The first related research publication with <a href="https://sites.google.com/view/rubenhip/home">Ruben Hipp</a> is available in <a href="https://www.econometricsociety.org/publications/quantitative-economics/2023/07/01/Estimating-Large-Dimensional-Connectedness-Tables-The-Great-Moderation-through-the-Lens-of-Sectoral-Spillovers"><em>Quantitative Economics</em></a>.</li>
<li>Stack: 
<code>pandas</code>, <code>numpy</code>, <code>time series forecasting</code>, <code>scikit-learn</code>, <code>python</code>, <code>SQL</code>, <code>glmnet</code>, <code>econometrics</code>, <code>statsmodels</code>, <code>vector auto-regression</code>, <code>networkx</code>, <code>matplotlib</code>, <code>MS Azure</code>
</details></li>
</ul>
</li>
</ul>
<p><br/><br/><br/></p>
<h2>Police Search Success Prediction and <span class="caps">AI</span> Fairness&nbsp;Analysis</h2>
<!-- LDSSA batch 4, 2020 -->

<p align="center"><img src="/assets/drawings/capstone-pipeline.png" alt="drawing" width="700"/></p>

<ul>
<li>
<p><strong>Challenge:</strong> Police searches in the <span class="caps">UK</span> were found to have inconsistent success rates and displayed signs of potential bias. The objective was to create a system to optimize search approval accuracy while minimizing&nbsp;discrimination.</p>
</li>
<li>
<p><strong>Solution:</strong> Using a <strong>tabular dataset</strong> of <span class="caps">UK</span> police data, I developed a <strong>machine learning model</strong> in to predict search approvals. The solution included detailed <strong>exploratory data analysis (<span class="caps">EDA</span>)</strong> to uncover stop and search biases. After manual <strong>feature engineering</strong> making use of geospacial information, a <code>sklearn</code> <strong>penalized logistic regression</strong> optimized with <strong>stochastic gradient descent</strong> outperformed a set of alternatives, including <strong>gradient boosting</strong> algorithms. Finally, the model was deployed via a responsive <code>Flask</code> <strong><span class="caps">API</span> endpoint</strong> as an accessible application on <code>Heroku</code>.</p>
</li>
<li>
<p><strong>Impact:</strong> The developed system successfully optimized police search decisions by <strong>improving search precision by 5%</strong> while <strong>reducing biases</strong> across minority groups, contributing to fairer and more effective stop-and-search&nbsp;practices.</p>
<p><details>
<br>
<summary><i>Click for additional information</i></summary></p>
<ul>
<li>Details and Links:
I conducted this case study for the purpose of the <a href="https://www.lisbondatascience.org/">Lisbon data science academy</a> (<a href="https://ldssa.github.io/wiki/">wiki</a>).
You can read detailed reports <a href="https://docs.google.com/document/d/17R__XRJQlo-NuDK9H9dAb_7soOW80RDrAHdl_L5oI_o/edit?usp=sharing">here</a> and <a href="https://docs.google.com/document/d/1R-ibDWOvTEMWNsaBjlbt3BOdZ4dMhwDJlwd4FwDt0KQ/edit?usp=sharing">here</a>
and view the code in the  repositories for <a href="https://github.com/felixbrunner/capstone">modeling</a> and <a href="https://github.com/felixbrunner/capstone-deploy">deployment</a>.</li>
<li>Stack: <code>pandas</code>, <code>numpy</code>, <code>Gradient boosting</code>, <code>XGBoost</code>, <code>scikit-learn</code>, <code>Python</code>, <code>Flask</code>, <code>Heroku</code>, <code>matplotlib</code>, <code>scipy</code>
<!-- *You can view the detailed solution on our GitHub repository or read the full case study here.* -->
</details></li>
</ul>
</li>
</ul>
<p><br/><br/><br/></p>
<!-- ## yetagain
library to estimate and study layered probabilistic time series models 

**Description:**

-->
        </div>
    </section>
        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<div id="aboutme">
        <p>
            <img width="100%" class="img-thumbnail" src="https://felixbrunner.github.io/assets/images/avatar.png"/>
        </p>
    <p>
      <strong>About Felix Brunner</strong><br/>
        Data Scientist and Quantitative Researcher
    </p>
</div><!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Github -->
<li class="list-group-item">
  <h4><i class="fa fa-github fa-lg"></i><span class="icon-label">GitHub Repos</span></h4>
  <div id="gh_repos">
    <p class="list-group-item">Status updating...</p>
  </div>
  <a href="https://github.com/felixbrunner">@felixbrunner</a> on GitHub
</li>
<!-- End Sidebar/Github -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2024 Felix Brunner
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>                <p><small>  <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en"><img alt="Creative Commons License" style="border-width:0" src="//i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a>
    &quot;<span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Felix Brunner</span>&quot; by <a xmlns:cc="http://creativecommons.org/ns#" href="https://felixbrunner.github.io" property="cc:attributionName" rel="cc:attributionURL">Felix Brunner</a> is
  licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="https://felixbrunner.github.io/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://felixbrunner.github.io/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="https://felixbrunner.github.io/theme/js/respond.min.js"></script>


    <script src="https://felixbrunner.github.io/theme/js/bodypadding.js"></script>

<!-- GitHub JS Code -->
<script type="text/javascript">
$(document).ready(function () {
  if (!window.jXHR) {
    var jxhr = document.createElement('script');
    jxhr.type = 'text/javascript';
    jxhr.src = 'https://felixbrunner.github.io/theme/js/jXHR.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(jxhr, s);
  }

  github.showRepos({
    user: 'felixbrunner',
    count: 3,
    skip_forks: true,
    target: '#gh_repos'
  });
});
</script>
<script src="https://felixbrunner.github.io/theme/js/github.js" type="text/javascript"></script>
<!-- End GitHub JS Code -->


</body>
</html>